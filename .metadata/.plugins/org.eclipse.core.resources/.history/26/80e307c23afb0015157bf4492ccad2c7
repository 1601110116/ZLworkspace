//============================================================================
// Name        : ZLMPI.cpp
// Author      : ZL
// Version     :
// Copyright   : ZL-CSPIC
// Description : Hello World in C++, Ansi-style
//============================================================================

#include <iostream>
#include <mpi.h>
#include <omp.h>
#include <time.h>
using namespace std;

int main(int argc, char**argv){

	MPI_Init(&argc, &argv);

	int l=30;
	char a[30];

	int this_rank;
	int total_process;
	MPI_Comm_rank(MPI_COMM_WORLD,&this_rank);
	MPI_Comm_size(MPI_COMM_WORLD,&total_process);
	MPI_Get_processor_name(a,&l);



	//send
	if(this_rank==0){
		int send_to=(this_rank==total_process-1?0:this_rank+1);
		MPI_Send(&this_rank,1,MPI_INT,send_to,0,MPI_COMM_WORLD);
	}
	//receive
	int receive_msg;
	MPI_Status recv_state;
	int listen_from=(this_rank==0?total_process-1:this_rank-1);
	MPI_Recv(&receive_msg,1,MPI_INT,listen_from,0,MPI_COMM_WORLD,&recv_state);
	cout <<"Node"<<this_rank<<"/"<<total_process<<" at "<<a<<" has "<<omp_get_num_procs()<<"threads"<< endl;
	cout <<()<<" processors are availible for omp"<<endl;

	if(this_rank!=0){
		int send_to=(this_rank==total_process-1?0:this_rank+1);
		MPI_Send(&this_rank,1,MPI_INT,send_to,0,MPI_COMM_WORLD);
	}

	double c=0;
	int b=0;
	int step=1;

	double t0=omp_get_wtime();


#pragma omp parallel
	{
		double ax=0;
		int bx=0;
#pragma omp critical
		cout<<omp_get_thread_num()<<"/"<<omp_get_num_threads()<<endl;
#pragma omp for
		for (int i = 0; i < 200000000; ++i) {
			ax+=step;
			bx+=step;
		}
#pragma omp critical
		{
			c+=ax;
			b+=bx;
		}
	}

	cout<<"a="<<c<<", b="<<b<<endl;

	cout<<"Node "<<this_rank<<": Total Time="<<(omp_get_wtime()-t0)*1000<<"ms"<<endl;


	MPI_Finalize();

	return 0;


}
